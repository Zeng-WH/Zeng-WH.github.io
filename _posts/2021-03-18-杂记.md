# 2021-03-18-杂记

## 投机

​	昨天花了点钱买了点比特币（54000刀）和莱特币（197刀），今天略有上涨（比特币（58000刀），莱特币207刀）就全部抛售。

## `nn.ModuleList`

https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList

可以像Python的列表一样像其中添加模型，当作迭代器使用。

```python
class MyModule(nn.Module):
    def __init__(self):
        super(MyModule, self).__init__()
        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])

    def forward(self, x):
        # ModuleList can act as an iterable, or be indexed using ints
        for i, l in enumerate(self.linears):
            x = self.linears[i // 2](x) + l(x)
        return x
```

## Python函数

有一些用法之前都忘记了。

**可变长参数**：参数前面加“*”的是元组参数；加”**”的是字典参数

```python
def foo(x, *tupleArgs, **dictArgs):
...     print("arg1 =", x)
...     print("arg2 =", tupleArgs)
...     print("arg3 =", dictArgs)
>>> foo(100, 1, 2, 3, a=1, b='world')
arg1 = 100
arg2 = (1, 2, 3)
arg3 = {'a': 1, 'b': 'world'}
```

**map函数：**

接受两个参数，第一个是一个函数，第二个是一个序列；序列中的每个元素应用到函数中，生成对应的值，最终返回一个序列（iterator）。

```
>>> list = [1,2,3,4,5]
>>> def square(x):
...     return x ** 2
... 
>>> ret = map(square, list)

```

遍历输出对应的结果

```
>>> for i in ret:
...     print(i)
... 
```

## 基于Transformers的文本分类

https://github.com/zhanlaoban/Transformers_for_Text_Classification

基于最新的 [huggingface](https://github.com/huggingface) 出品的 [transformers](https://github.com/huggingface/transformers/releases/tag/v2.2.2) v2.2.2代码进行重构。为了保证代码日后可以直接复现而不出现兼容性问题，这里将 [transformers](https://github.com/huggingface/transformers/releases/tag/v2.2.2) 放在本地进行调用。

**model_type：**

-  bert
-  bert_cnn
-  bert_lstm
-  bert_gru
-  xlnet
-  xlnet_cnn
-  xlnet_lstm
-  xlnet_gru
-  albert

