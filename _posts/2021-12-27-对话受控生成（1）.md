---
layout:     post
title:      "对话受控生成（1）"
subtitle:   从Control Dialogue Generation 开始调研！
date:       2022-02-25 22:30:00
author:     "Andrew Zeng"
tags:
    对话生成
---
1. 受控生成包括哪些形式？
2. 传统的受控生成方式有哪些？
3. prefix参与受控生成的方式有哪些？

受控生成将多种类型的信号（length specifications; high-lighted phrases）而不是输入文本加入到生成模型中。

# CONTROL PREFIXES for Text Generation
1. Control Prefixs的原理，作用？√
2. attributes是怎么弄进去的？√
3. 效果如何？8行

作者声称CONTROL PREFIXES可以将input-depent information包括在prompt中。收到传统的受生成方法使用controllable attributes来生成想要的qualities的目标句子。
![43png](https://github.com/Zeng-WH/MarkdownPic/raw/main/2021-03-19/43.PNG)
在论文中，作者仅仅考虑作为guidance signal的attributes由discrete labels.
模型输入的样本形式是<img src="http://chart.googleapis.com/chart?cht=tx&chl= Z=\{<X^{j},Y^{j}, G^{j}>\}_{j=1,\cdots,N}" style="border:none;">, 其中<img src="http://chart.googleapis.com/chart?cht=tx&chl= G^{j}" style="border:none;">表示第j个样本的conditional attribute-level information.
思路就是存在一个通用的task prefix <img src="http://chart.googleapis.com/chart?cht=tx&chl= P_{\theta}" style="border:none;">(如同prefix-tuning), 在训练的过程随着输入而改变的Control Prefixs, 具体说来就是根据样本的中的G选择对应的Control Prefixs参与训练。

![44png](https://github.com/Zeng-WH/MarkdownPic/raw/main/2021-03-19/44.PNG)

效果感觉8太行
## Zero-shot Learning
在WebNLG的实验中，测试集存在着两种情况，一种样本对应Atrribude imformation在训练集中出现过，这样可以直接使用对应的control prefix; 但存在着样本对应的Attribute information在训练集未出现过的情形。
因此，作者将所有的Attribude imformation对应的信息映射到Glove embedding上，对于那些未见过的attribute imformation, 就使用那些具有最高cosine similarity的attribude对应的cotrol prefix.
效果：
![45png](https://github.com/Zeng-WH/MarkdownPic/raw/main/2021-03-19/45.PNG)

OOV指的是随机拿2%的数据训练

# Response Generation with Context-Aware Prompt Learning
作者提出了让prompt encoder能够基于input dialogue context更好地生成prompt的方法。
![46png](https://github.com/Zeng-WH/MarkdownPic/raw/main/2021-03-19/46.PNG)

prefix在设计时将prompt encoder设计成fully connected形式，将prompt utterance转化成hidden states序列：
<img src="http://chart.googleapis.com/chart?cht=tx&chl= s_{1},\cdots,s_{k}=f_{\theta}(e(p_{1}), \cdots, e(p_{k}))" style="border:none;">

而DialogPrompt在设计时，将Prompt Encoder设计成Autoregressive Transformer, 先利用Pretrained GPT-2(Frozen) 计算出Context的hiddene states, 然后作为prompt encoder的past hidden states. 来生成prompt encodings
<img src="http://chart.googleapis.com/chart?cht=tx&chl= [\tilde{s_{1}}, \cdots, \tilde{s_{k}}]" style="border:none;"> ：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= \tilde{s_{i}}=Transformer_{prompt}(p_{i},h_{1},\cdots,h_{m},\tilde{s_{<i}})" style="border:none;">


![47png](https://github.com/Zeng-WH/MarkdownPic/raw/main/2021-03-19/47.PNG)


有作者提供的结果可以看，DialogPrompt比Fine-Tuning效果要好。
作者从Prompt Encoder的结构上下了功夫，不清楚参数量如何




